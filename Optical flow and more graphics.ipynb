{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sransom/pyart/pyart/graph/cm.py:104: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'red' in spec:\n",
      "/home/sransom/pyart/pyart/graph/cm_colorblind.py:32: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if 'red' in spec:\n"
     ]
    }
   ],
   "source": [
    "#Load some packages to be used in this program\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy  as sp\n",
    "import numpy  as np\n",
    "import xarray as xr\n",
    "import pyart  as pyart\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import cv2\n",
    "import imageio\n",
    "from imgpy import Img\n",
    "import pickle\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import sys\n",
    "import moviepy.editor as mp\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import matplotlib.animation as animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to crop image\n",
    "def crop(img,box):\n",
    "    with Img(fp=img) as im:\n",
    "        im.crop(box=box)\n",
    "        im.save(fp=img[0:-4] + '_cropped.gif')\n",
    "\n",
    "#make function to convert to avi:\n",
    "def gif2avi(gifpath):\n",
    "    clip = mp.VideoFileClip(gifpath)\n",
    "    clip.write_videofile(gifpath[0:-4] + \".avi\", codec = 'rawvideo')\n",
    "    avipath = gifpath[0:-4] + \".avi\"\n",
    "    return avipath\n",
    "\n",
    "#make function to turn resize gifs such that they are the same dimensions as the masks\n",
    "def resize(imagepath,dim1,dim2):\n",
    "    image = Image.open(imagepath)\n",
    "    image = image.resize((dim1, dim2), PIL.Image.ANTIALIAS)\n",
    "    image.save(imagepath)\n",
    "    resized_image = imageio.read(imagepath)\n",
    "    return resized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:  35%|███▌      | 84/240 [00:00<00:00, 836.87it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity_cropped.avi.\n",
      "Moviepy - Writing video /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity_cropped.avi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity_cropped.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity x2_cropped.avi.\n",
      "Moviepy - Writing video /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity x2_cropped.avi\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity x2_cropped.avi\n"
     ]
    }
   ],
   "source": [
    "#Import gifs\n",
    "reflectivity_gif =   '/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity.gif'\n",
    "#total_power_gif  =   '/home/sransom/pyth/EG_Utqiagvik_gridded/total_power.gif'\n",
    "reflectivity_gifx2 = '/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity x2.gif'\n",
    "\n",
    "#Crop gifs\n",
    "box_top_left= (109, 87)\n",
    "box_btm_rght = (643,486)\n",
    "box = box_top_left + box_btm_rght\n",
    "\n",
    "#Crop the images\n",
    "crop(reflectivity_gif,box)\n",
    "#crop(total_power_gif,box)\n",
    "crop(reflectivity_gifx2,box)\n",
    "\n",
    "\n",
    "#convert to avis:\n",
    "reflectivity_cropped   = gif2avi(\"/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity_cropped.gif\"   )\n",
    "#total_power_cropped    = gif2avi(\"/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity_cropped.gif\"   )\n",
    "reflectivity_croppedx2 = gif2avi(\"/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/reflectivity x2_cropped.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Every time a new point starts being tracked, run this def to add it to a directory of its history\n",
    "def add_point_directory(point_directory,new_points,tiempo):\n",
    "    PDlen = len(point_directory)\n",
    "    for pnum in range(PDlen, PDlen + len(new_points)-1):\n",
    "        point_directory['point' + str(pnum)] = {\n",
    "            'coords'  : [],\n",
    "            'last_loc': [],\n",
    "            'time'    : [],\n",
    "            'u'       : [],\n",
    "            'v'       : [],\n",
    "            '__doc__' : \\\n",
    "                \"'coords' is a 2-element list ('[xnew, ynew]') giving the current coordinates of the optical \" \\\n",
    "                \"flow program's best guess of the new location of the feature being tracked.\" \\\n",
    "                \"'last_loc' is a 2-element list ([xold, yold]) giving the the coordinates of the feature from \" \\\n",
    "                \"the last frame which the optical flow algorithm has tracked to the location specified by 'coords'.\" \\\n",
    "                \"\\n 'time' is the time, in minutes, since the first frame.\" \\\n",
    "                \"\\n 'u' and 'v' are the mean zonal and meridional velocities (km/hr), respectively, of the feature \" \\\n",
    "                \"\\n between the last point ([xold, yold]) and the latest point ([xnew, ynew]).\" \n",
    "        }\n",
    "\n",
    "        (x, y) = new_points[pnum-PDlen][0]\n",
    "        point_directory['point' + str(pnum)]['coords'].append([x, y])\n",
    "        point_directory['point' + str(pnum)]['time'].append(tiempo)\n",
    "    return point_directory\n",
    "\n",
    "#Make def to calculate distance between two points\n",
    "def dist(p1,p2):\n",
    "    distance = np.sqrt((p1[0]-p2[0])**2 + (p1[1]-p2[1])**2)\n",
    "    return distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_directory.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = reflectivity_cropped\n",
    "location = '/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/OF_frames/'\n",
    "borderimage = imageio.imread('/home/sransom/pyth/stationary mask boundary 399x534.png')\n",
    "maskborder = np.asarray(borderimage)[:,:,0:3]\n",
    "landshape = imageio.imread('/home/sransom/pyth/utqiagvik mask 399x534.png')[:,:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate which pixel the boundary starts at \n",
    "#define a function to create a mask based on this png\n",
    "def find_boundary(im):\n",
    "    width =  np.shape(im)[1]        # get borderimageage size\n",
    "    height =  np.shape(im)[0]\n",
    "    notborder = im[0,0]   # find color that corresponds with not the border\n",
    "    border = []\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            if im[y,x] == notborder:\n",
    "                continue  # mask on the point if it is ocean\n",
    "            else:\n",
    "                border.append(width)\n",
    "    return border\n",
    "coast = find_boundary(borderimage[:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def optical_flow_Lucas_Kanade(file,location):\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 100 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors to demarkate specific points\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "#create empty point directory to add to later\n",
    "point_directory = {}\n",
    "#create dictionary storing individual frames:\n",
    "animated_frames = {\n",
    "    'with_ice'    : {},\n",
    "    'just_tracks' : {}\n",
    "}\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "print('Finding features to track.')\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define first set of tracking features' coords:\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "\n",
    "# Add these initial coords to the point_directory:\n",
    "point_directory = add_point_directory(point_directory,p0,0)\n",
    "print(str(len(p0)) + ' starting features found.')\n",
    "\n",
    "points_used_this_timestep = [len(p0)]\n",
    "\n",
    "# Create an ice tracks image for drawing purposes\n",
    "tracks = np.zeros_like(old_frame)\n",
    "\n",
    "#flag that the point_adding algorithm has not been applied yet:\n",
    "its_new_points = False\n",
    "\n",
    "feature_lines = []\n",
    "#while(1):\n",
    "for count in range(1,119):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "    try:\n",
    "        good_old = p0[st==1]\n",
    "        good_new = p1[st==1]\n",
    "        \n",
    "    except TypeError:\n",
    "        raise Warning(\"If you're seeing this error, your (all points moved off-screen) catchsafe probably isn't working\")\n",
    "        if count != 118:\n",
    "            print('All features moved off-screen, adding ' + str(len(p0)) + ' new features.')\n",
    "            p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "            point_directory = add_point_directory(point_directory,p0,count*15)\n",
    "        continue\n",
    "    points_used_in_this_loop = []\n",
    "    # draw the tracks\n",
    "    my_frame = frame.copy()\n",
    "    for (new,old) in zip(good_new,good_old):\n",
    "        try:\n",
    "            xold, yold = old.ravel()\n",
    "            xnew, ynew = new.ravel()\n",
    "            \n",
    "            #find the number this point is indexed as \n",
    "            already_IDed = False #reset ambiguity check\n",
    "            if its_new_points:\n",
    "                contenders = range(old_dic_length)\n",
    "            else:\n",
    "                contenders = range(len(point_directory))\n",
    "            for contendernum in contenders:\n",
    "                try:\n",
    "                    contender_coords = point_directory['point' + str(contendernum)]['coords'][-1]\n",
    "                except IndexError:\n",
    "                    pointID = contendernum\n",
    "                if contender_coords == [xold, yold]:\n",
    "           #         if already_IDed:\n",
    "           #             raise Warning('point ' + str(contendernum) + ' is ambiguous with a previous point: ' + str(pointID))\n",
    "           #             del point_ID #ensure that if no point is IDed that it doesn't just register as the last point\n",
    "                    pointID = contendernum\n",
    "                    already_IDed = True #Mark this count's point as already ID'ed\n",
    "            its_new_points = False #indicate that these aren't new points this round\n",
    "            \n",
    "            point_directory['point' + str(pointID)]['coords'].append([xnew, ynew])\n",
    "            point_directory['point' + str(pointID)]['last_loc'].append([xold, yold])\n",
    "            point_directory['point' + str(pointID)]['time'].append(count*15)\n",
    "            points_used_in_this_loop.append(pointID)\n",
    "            tracks = cv2.line(tracks, (xold, yold), (xnew, ynew), tuple(color[pointID].tolist()), 2)\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        #tracks = cv2.circle(tracks,(a,b),5,color[i].tolist(),-1)\n",
    "    \n",
    "    frame[frame==255.] = 0\n",
    "    img = cv2.add(frame,tracks)\n",
    "    img = frame + tracks + maskborder + landshape\n",
    "    just_tracks = tracks + maskborder + landshape\n",
    "    animated_frames['with_ice']['frame' + str(count)]:img\n",
    "    animated_frames['just_tracks']['frame' + str(count)]:just_tracks\n",
    "\n",
    "    cv2.imshow('frame',just_tracks)\n",
    "    cv2.imwrite(location + 'reflectivity' + str(count) + '.png',just_tracks)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    #print(k)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "    \n",
    "    print(len(p0))\n",
    "\n",
    "    #add points if the program is running low on points\n",
    "    p0len = len(p0)\n",
    "    if p0len < 6: \n",
    "        old_dic_length = len(point_directory)\n",
    "        pnew = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        #check if new point is too near an already discovered point (i.e. not a new point); make index of valid new points\n",
    "        valid_pnews = np.ones(len(pnew),dtype = bool)\n",
    "        for remaining_point in range(p0len):\n",
    "            for new_point in range(len(pnew)):\n",
    "                if dist(pnew[new_point,:][0],p0[remaining_point,:][0]) < 10: #check if dist b/w points is < 10px\n",
    "                    valid_pnews[new_point] = False\n",
    "        #select just valid pnews:\n",
    "        pnew = pnew[valid_pnews]\n",
    "        p0 = np.asarray(tuple(p0) + tuple(pnew))\n",
    "        \n",
    "        #Add new points' data to the point directory\n",
    "        point_directory = add_point_directory(point_directory,pnew,count*15)\n",
    "        \n",
    "        \n",
    "        #flag that these are new points\n",
    "        its_new_points = True\n",
    "        print('Fewer than 5 points remaining after ' + str(count) + ' iterations; added ' + str(len(pnew)) + ' new features.')\n",
    "    print('p0 length = ' + str(len(p0)) + ' after ' + str(count) + ' iterations; points used this loop: ' + str(points_used_in_this_loop))\n",
    "    points_used_this_timestep.append(len(points_used_in_this_loop))\n",
    "\n",
    "    #cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print('yeet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### ffmpeg -f image2 -r 1/5 -i image%05d.png -vcodec mpeg4 -y movie.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_directory['point' + str(contendernum)]['coords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_directory_save_location = open(\"/home/sransom/pyth/point_directory.pkl\",\"wb\")\n",
    "pickle.dump(point_directory,point_directory_save_location)\n",
    "point_directory_save_location.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(point_directory['point0']['__doc__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate distances between latitudes\n",
    "latrange = [-157.0, -156.2]\n",
    "lonrange = [71.2, 71.5]\n",
    "latrangemeters = np.sin(np.diff(latrange) * np.pi/180)*6.371e6\n",
    "lonrangemeters = np.sin(np.diff(lonrange) * np.pi/180)*6.371e6\n",
    "resolution = 401\n",
    "#define conversion factor from px to meters\n",
    "px_per_m_lat = resolution/latrangemeters\n",
    "px_per_m_lon = resolution/lonrangemeters\n",
    "#define conversion factor from pixels per second to km perhour\n",
    "pxps2metersph_lat = 3600/px_per_m_lat\n",
    "pxps2metersph_lon = 3600/px_per_m_lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make motion vectors from coords listed in point_directory\n",
    "for pnum in range(len(point_directory.keys())):\n",
    "    #extract this point's data:\n",
    "    point = point_directory['point' + str(pnum)]\n",
    "    #find initial position and time of this point:\n",
    "    x0, y0 = point['coords'][0]\n",
    "    time0  = point['time'][0]*3600\n",
    "    #reset feature position index\n",
    "    coordnum = 0\n",
    "    #reset velocities for this point so that we aren't just adding new extraneous data:\n",
    "    point_directory['point' + str(pnum)]['u'] = []\n",
    "    point_directory['point' + str(pnum)]['v'] = []\n",
    "    #begin looping through this point's coordinates:\n",
    "    while(1):\n",
    "        try:\n",
    "            x1, y1 = point['coords'][coordnum]\n",
    "            time1  = point['time'][coordnum]*3600\n",
    "            \n",
    "            #calculate u and v vectors and register them in the point directory:\n",
    "            point_directory['point' + str(pnum)]['u'].append((x1-x0)/(time1-time0)*pxps2metersph_lat)\n",
    "            point_directory['point' + str(pnum)]['v'].append((y1-y0)/(time1-time0)*pxps2metersph_lon)\n",
    "            \n",
    "            #reset indices for next loop iteration\n",
    "            x0, y0, time0 = (x1, y1, time1)\n",
    "            coordnum += 1\n",
    "            \n",
    "            \n",
    "        #once last tracked position is reached, break to next point:\n",
    "        except IndexError: \n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lobf(this_axis):\n",
    "    velnum = np.zeros(120)\n",
    "    velsum = np.zeros(120)\n",
    "    for lineas in this_axis.get_lines():\n",
    "        xdata = lineas.get_xdata()\n",
    "        ydata = lineas.get_ydata()\n",
    "        #timeindex = np.array([int(x/15) for x in xdata])\n",
    "        for i, a in enumerate(xdata):\n",
    "            velnum[int(a/15)] += float(1)\n",
    "            velsum[int(a/15)] += float(ydata[i])\n",
    "    lobf = velsum/velnum\n",
    "    return lobf\n",
    "        #velnum[timeindex] += 1\n",
    "        #velsum[timeindex] += ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lobf(axes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "120*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,60,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot velocities\n",
    "higo = plt.figure()\n",
    "higo, axes = plt.subplots(2,1,figsize = (20,20))\n",
    "plt.subplots_adjust(hspace = .2)\n",
    "for key in point_directory.keys():\n",
    "    point = point_directory[key]\n",
    "    axes[0].plot(point['time'],point['u'], linewidth = 2)\n",
    "    axes[0].set_title('Zonal velocities')\n",
    "    axes[0].set_ylabel('Velocity (m/hr)')\n",
    "    axes[0].set_ylim(-200,200)\n",
    "    axes[0].set_xlim(0,1750)\n",
    "    axes[0].set_xlabel('time (minutes)')\n",
    "    axes[1].plot(point['time'],point['v'], linewidth = 2)\n",
    "    axes[1].set_title('Meridional velocities')\n",
    "    axes[1].set_ylabel('Velocity (m/hr)')\n",
    "    axes[1].set_ylim(-50,50)\n",
    "    axes[1].set_xlim(0,1750)\n",
    "    axes[1].set_xlabel('time (minutes)')\n",
    "axes[0].plot(np.arange(0,1800,15),lobf(axes[0]),linewidth = 4, color = 'k')\n",
    "axes[1].plot(np.arange(0,1800,15),lobf(axes[1]),linewidth = 4, color = 'k')\n",
    "higo.savefig('/home/sransom/pyth/papergraphics/velocities.png', bbox_inches = 'tight')\n",
    "    #find mean velocities in each array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot number of points plotted by timestep\n",
    "higo = plt.figure()\n",
    "plt.plot(points_used_this_timestep)\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Number of features being tracked')\n",
    "plt.suptitle('Number of points being tracked \\n by optical flow per timestep: \\n')\n",
    "higo.savefig('/home/sransom/pyth/papergraphics/points_tracked.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mygrid = pyart.io.read_grid('/home/sransom/pyth/EG_Utqiagvik_gridded/grids/BRW190120001204.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "egdata = np.ma.getdata(mygrid.fields['reflectivity']['data'])\n",
    "egdata = egdata.ravel()\n",
    "egdata = egdata[~np.isnan(egdata)]\n",
    "\n",
    "plt.hist(egdata, bins= np.linspace(10,40,30), rwidth = .9, density = True)\n",
    "plt.xlabel('Equivalent reflectivity factor (dBZ)')\n",
    "plt.ylabel('Percentage of data in range')\n",
    "plt.suptitle('PDF of reflectivity values excluding land values')\n",
    "plt.savefig('/home/sransom/pyth/papergraphics/power_spectrum_sans_land.png', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('no need to run past here if running whole notebook. type Ctrl+f+yeeet to find this point')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#def optical_flow_Lucas_Kanade(file,location):\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 100 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "#create empty point directory to add to later\n",
    "point_directory = {}\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "print('Finding features to track.')\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "point_directory = add_point_directory(point_directory,p0)\n",
    "print(str(len(p0)) + ' starting features found.')\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "feature_lines = []\n",
    "#while(1):\n",
    "for count in range(119):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "   # print(count)\n",
    "   # print(p1)\n",
    "   # print(st)\n",
    "    #try:\n",
    "    # Select good points\n",
    "    good_new = good_old = np.zeros((len(st),2),dtype = np.float32)\n",
    "    for yeet in range(len(st)):\n",
    "        if st[yeet] == 1:\n",
    "            good_new[yeet] = p1[yeet]\n",
    "            good_old[yeet] = p0[yeet]\n",
    "        else:\n",
    "            good_old[yeet] = 0\n",
    "            good_new[yeet] = 0\n",
    "        ##If the results of attempting the above is just too abominable, just replace it with the following:\n",
    "        #good_new = p1[st==1]\n",
    "        #good_old = p0[st==1]\n",
    "   # except TypeError:\n",
    "   #     print('All features moved off-screen, adding ' + str(len(p0)) + ' new features.')\n",
    "   #     p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "   #     point_directory = add_point_directory(point_directory,p0)\n",
    "   #     continue\n",
    "    p1len = len(p1[p1!=0])\n",
    "    if p1len < 3: #add points if the program is running low on points\n",
    "        pnew = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        #check if new point is too near an already discovered point (i.e. not a new point); make index of valid new points\n",
    "        valid_pnews = np.ones(len(pnew),dtype = bool)\n",
    "        for remaining_point in range(p1len-1):\n",
    "            for new_point in range(len(pnew)-1):\n",
    "                try:\n",
    "                    if dist(pnew[new_point,:],p1[p1!=0][remaining_point,:]) < 10: #check if dist b/w points is < 10px\n",
    "                        valid_pnews[new_point] = False\n",
    "                except IndexError:\n",
    "                    if dist(pnew[new_point,:][0],p1[p1!=0]) < 10: #check if dist b/w points is < 10px\n",
    "                        valid_pnews[new_point] = False        #select just valid pnews:\n",
    "        pnew = pnew[valid_pnews]\n",
    "        p1 = np.asarray(tuple(p1.ravel()) + tuple(pnew.ravel()))\n",
    "        point_directory = add_point_directory(point_directory,p1)\n",
    "        print('Fewer than 3 points remaining after ' + str(count) + ' iterations; added ' + str(len(pnew)) + ' new features.')\n",
    "\n",
    "    # draw the tracks\n",
    "    my_frame = frame.copy()\n",
    "    for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "        try:\n",
    "            a,b = new.ravel()\n",
    "            point_directory['point' + str(i)].append([a,b])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        try:\n",
    "            c,d = old.ravel()\n",
    "            point_directory['point' + str(i)].append([c,d])\n",
    "        except AttributeError:\n",
    "            continue\n",
    "        mask = cv2.line(mask, (a,b),(c,d), tuple(color[i].tolist()), 2)\n",
    "        mask = cv2.circle(mask,(a,b),5,color[i].tolist(),-1)\n",
    "    frame[frame==255.] = 0\n",
    "    img = cv2.add(frame,mask)\n",
    "\n",
    "    cv2.imshow('frame',img)\n",
    "    cv2.imwrite(location,img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    #print(k)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print('yeet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#def optical_flow_Lucas_Kanade(file,location):\n",
    "cap = cv2.VideoCapture(file)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 100 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "\n",
    "#create empty point directory to add to later\n",
    "point_directory = {}\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "print('Finding features to track.')\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "add_point_directory(point_directory,p0)\n",
    "print(str(len(p0)) + ' starting features found.')\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "feature_lines = []\n",
    "#while(1):\n",
    "for count in range(119):\n",
    "    ret,frame = cap.read()\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "\n",
    "   # print(count)\n",
    "   # print(p1)\n",
    "   # print(st)\n",
    "    try:\n",
    "        # Select good points\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    except TypeError:\n",
    "        print('All features moved off-screen, adding ' + str(len(p0)) + ' new features.')\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        add_point_directory(point_directory,p0)\n",
    "        continue\n",
    "\n",
    "    if len(p1) < 3: #add points if the program is running low\n",
    "        pnew = cv2.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "        p0 = np.asarray(tuple(p0.ravel()) + tuple(pnew.ravel()))\n",
    "        print('Fewer than 3 points remaining after ' + str(count) + ' iterations...added ' + str(len(pnew)) + ' new features.')\n",
    "\n",
    "    show_ice = True\n",
    "        \n",
    "    # draw the tracks\n",
    "    if show_ice:\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "        frame[frame==255.] = 0\n",
    "        img = cv2.add(frame,mask)\n",
    "    else:\n",
    "        my_frame = frame.copy()\n",
    "        for i,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "            a,b = new.ravel()\n",
    "            c,d = old.ravel()\n",
    "            mask = cv2.line(mask, (a,b),(c,d), tuple(color[i].tolist()), 2)\n",
    "            #mask = cv2.circle(mask,(a,b),5,color[i].tolist(),-1)\n",
    "        img = mask\n",
    "\n",
    "    cv2.imshow('frame',img)\n",
    "    #cv2.imwrite(location,img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    #print(k)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "#cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "print('yeet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_directory.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = '/home/sransom/pyth/EG_Utqiagvik_gridded/sans_ice/optical_flow_reflectivity x2.png'\n",
    "optical_flow_Lucas_Kanade(reflectivity_cropped,location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise ValueError('Terminate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optical_flow_dense_method(file):\n",
    "    cap = cv2.VideoCapture(file)\n",
    "\n",
    "    ret, frame1 = cap.read()\n",
    "    prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY)\n",
    "    hsv = np.zeros_like(frame1)\n",
    "    hsv[...,1] = 255\n",
    "\n",
    "    while(1):\n",
    "        ret, frame2 = cap.read()\n",
    "        next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "        hsv[...,0] = ang*180/np.pi/2\n",
    "        hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "        rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        cv2.imshow('frame2',rgb)\n",
    "        k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('/home/sransom/opticalfb.png',frame2)\n",
    "            cv2.imwrite('/home/sransom/opticalhsv.png',rgb)\n",
    "        prvs = next\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_flow_dense_method(total_power_cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar = pyart.io.read('/nfs/gce/projects/digr/xsapr_nsa/BRW190120002403.RAWTA32.maint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar.range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
